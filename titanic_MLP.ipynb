{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fV1_Ija-X5mgEOntMiPq1swFXXJD25Fb",
      "authorship_tag": "ABX9TyNYpx1dREotbr09GL6l4878",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemeZamanian/Titanic/blob/master/titanic_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IH4X_MVBnaA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import inv"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Qe-zqRuPExy8",
        "outputId": "dd1e1589-40cc-47d7-8e93-07ccbda89982"
      },
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "data=data.replace([\"male\",\"female\"],[0,1])\n",
        "data=data.replace([\"S\",\"C\",\"Q\"],[0,1,2])\n",
        "data=data.fillna(0)\n",
        "data.head()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500      0       0.0\n",
              "1            2         1       1  ...  71.2833    C85       1.0\n",
              "2            3         1       3  ...   7.9250      0       0.0\n",
              "3            4         1       1  ...  53.1000   C123       0.0\n",
              "4            5         0       3  ...   8.0500      0       0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgaZ-vZfJVaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93227d4a-cbb1-4bbb-f10f-bdbe1aa06079"
      },
      "source": [
        "Y_train=data[['Survived']]\n",
        "X_train=data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "Y_train=np.array(Y_train)\n",
        "X_train=np.array(X_train)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7)\n",
            "(891, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfQa2ujRYyVw"
      },
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Dense(7,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(512,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(2,activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRX0ltfHB6TG"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqdjXgM0DZW6",
        "outputId": "43151db2-144e-422c-b7b1-29a64cf38ec1"
      },
      "source": [
        "out=model.fit(X_train,Y_train,epochs=500)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.5993\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.6229\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7863 - accuracy: 0.6004\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6375\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6285\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6566\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.6521\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6128\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6577\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.6296\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6386\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6364\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6397\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6622\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.6498\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6566\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6510\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6678\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.6476\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6588\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6768\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6453\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6655\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.6599\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6611\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6577\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6543\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6689\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6790\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6712\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6644\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6611\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6667\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6700\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6622\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6655\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6824\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.6319\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6768\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6611\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6498\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6689\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6622\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6723\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6599\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6824\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6644\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6655\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6723\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6745\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6543\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6667\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6700\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6790\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6667\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6734\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6700\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6678\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6813\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6779\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6756\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6723\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6891\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6992\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6846\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6801\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6790\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6857\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6824\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6790\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6790\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6835\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6723\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6813\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6779\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6891\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6723\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6914\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6869\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6756\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6936\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6756\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6824\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6869\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6891\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6857\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7071\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6824\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6835\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6914\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6902\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6846\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6970\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6880\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6857\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6880\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6914\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6902\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6813\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6813\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6880\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6813\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.7059\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6936\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6835\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6700\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6947\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6891\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6958\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6914\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6869\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6813\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6891\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6846\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6902\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7048\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6981\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6891\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6958\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6981\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6869\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6970\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6936\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.6992\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6936\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.6869\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6880\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6846\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6846\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6981\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6925\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6846\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6970\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6958\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6970\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6947\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6914\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6790\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7003\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6914\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6992\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6835\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6902\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6970\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6936\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6981\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6790\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6947\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6947\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6835\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6902\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6958\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6970\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7015\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7048\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6914\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.6891\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7015\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6846\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7082\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6914\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6947\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6992\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6835\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7003\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6992\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6958\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.6958\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7093\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6992\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6824\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6902\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6947\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6992\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7026\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7048\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6992\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6958\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6936\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6958\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7003\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6857\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7015\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6869\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7059\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.7093\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7093\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6970\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7093\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6970\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7026\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7003\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7071\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6857\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7026\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6936\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7149\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7059\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6902\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7082\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7015\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6936\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7116\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7048\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7037\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7026\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7026\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7205\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7015\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7048\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.7071\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7217\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7059\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7172\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7048\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7273\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7037\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7205\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7183\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7306\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7104\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7194\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7250\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7205\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7239\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7138\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7194\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7160\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7172\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7104\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7116\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7228\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7160\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7048\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7138\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7239\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7160\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7194\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7295\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6891\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7250\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7205\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7116\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7172\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7149\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7116\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7003\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7217\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7104\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7273\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7205\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7183\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7228\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7026\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7205\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7318\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7250\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7104\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7160\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7228\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7015\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7239\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7239\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7217\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7284\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7228\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7172\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7273\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7284\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7037\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7149\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7340\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7363\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7385\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7284\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7318\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7194\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7262\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7138\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7340\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7329\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7217\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7318\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7250\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7160\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7295\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7160\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7295\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7093\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7284\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7228\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7385\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7363\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7318\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7217\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7351\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7262\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7374\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7329\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7363\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7194\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7340\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7340\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7441\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7228\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7329\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7262\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7340\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7340\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7217\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7374\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7250\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7273\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7363\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7340\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7306\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7385\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7284\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7306\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7329\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7262\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7273\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7407\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7306\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7273\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7374\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7351\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7239\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7385\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7385\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7273\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7452\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7419\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7295\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7194\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7306\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7441\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7396\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7407\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7306\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7430\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7374\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7430\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7295\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7497\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7475\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7396\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7396\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7351\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7385\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7385\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7351\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7407\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7542\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7363\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7520\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7318\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7374\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7363\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7419\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7452\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7486\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7464\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7464\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7553\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7385\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7508\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7520\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7520\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7464\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7396\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7497\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7407\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7475\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7531\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7486\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7464\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7351\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7452\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7587\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7407\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7553\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7452\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7598\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7497\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7587\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7666\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7666\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7441\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7531\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7722\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7643\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7385\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7553\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7621\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7565\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7452\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7475\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7688\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7643\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7643\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7609\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7688\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7464\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7677\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7587\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7800\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7778\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7744\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7800\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7755\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7722\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7643\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7654\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7632\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7452\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7587\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7542\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7441\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7699\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7677\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7609\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7778\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7621\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7598\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7789\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7688\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7710\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7621\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7811\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7666\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7553\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7699\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7744\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7767\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7643\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7789\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7609\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7565\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7789\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7767\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7733\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7609\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7755\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7677\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7598\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7666\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7722\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7744\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7497\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7497\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7688\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7767\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7755\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7643\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7609\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7856\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7879\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7845\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7621\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7755\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7733\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7800\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7755\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7677\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7823\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7710\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7912\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7576\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7621\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7834\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7778\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7722\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7778\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7767\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7733\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7688\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7677\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7901\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7800\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7924\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7845\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7767\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7677\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7778\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7722\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7755\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7845\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7946\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7924\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7811\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7688\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7924\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7856\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7789\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7879\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7823\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7666\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7733\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "c9aA8Irws_dr",
        "outputId": "76b29caf-5cee-46c1-85b1-0f3620e86a9b"
      },
      "source": [
        "plt.plot(out.history['loss'])\n",
        "plt.plot(out.history['accuracy'])"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7eff4825ed10>]"
            ]
          },
          "metadata": {},
          "execution_count": 238
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xAA-Z_A_mU_"
      },
      "source": [
        "data_test = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "data_test=data_test.replace([\"male\",\"female\"],[0,1])\n",
        "data_test=data_test.replace([\"S\",\"C\",\"Q\"],[0,1,2])\n",
        "data_test=data_test.fillna(0)\n",
        "\n",
        "X_test=data_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "\n",
        "Y = pd.read_csv('/content/drive/MyDrive/gender_submission.csv')\n",
        "Y_test = Y[['Survived']]\n",
        "\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TfaJjM2G-lX",
        "outputId": "53409a69-7a60-4fe0-ae64-802586df42ff"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.397794246673584, 0.8923444747924805]"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqSmiOzNH5LO",
        "outputId": "691becfa-fc65-4174-9240-a641b5406345"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "predict = np.argmax(Y_pred, axis = 1)\n",
        "predict"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouaPqXgCd-93",
        "outputId": "0aa399ec-c200-4885-a0c9-b9e26de0c6ab"
      },
      "source": [
        "model.save('/content/drive/MyDrive')"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCDk2hY3eTCO"
      },
      "source": [
        "class KNearestNeighbors:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        \n",
        "    def fit(self, x_train, y_train):\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.number_class = len(np.unique(y_train))\n",
        "        \n",
        "    def distance(self,a,b):\n",
        "        dis = np.sqrt(np.sum((a-b)**2, axis = 1))\n",
        "        return dis\n",
        "        \n",
        "    def nearestNeighbors(self, x_test):\n",
        "        point_dist=[]\n",
        "        for x in x_test:\n",
        "            point_dist.append(self.distance(x,self.x_train))\n",
        "            \n",
        "        neigh_ind=[]\n",
        "        for row in point_dist:\n",
        "            near_neighbor = np.argsort(row)[:self.k]\n",
        "            neigh_ind.append(near_neighbor)\n",
        "            \n",
        "        return np.array(neigh_ind)\n",
        "    \n",
        "    def predict(self, x_test):\n",
        "        neighbors = self.nearestNeighbors(x_test)\n",
        "        y_pred=[]\n",
        "        for neighbor in neighbors:\n",
        "            y_pred.append(np.argmax(np.bincount(self.y_train[neighbor])))\n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def evaluate(self,x_test,y_test):\n",
        "        temp=[]\n",
        "        c=0\n",
        "        self.x_test=x_test\n",
        "        self.y_test=y_test\n",
        "        temp=self.predict(self.x_test)\n",
        "        for i in range(len(self.x_test)):\n",
        "            if temp[i]==self.y_test[i]:\n",
        "                c+=1\n",
        "        ev=c/len(y_test)\n",
        "        return ev"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dajw-vpxf44m",
        "outputId": "ab3d3963-c173-41c4-c1ca-3def10e07bde"
      },
      "source": [
        "Y_train = Y_train.reshape(-1,)\n",
        "knn=KNearestNeighbors(k=5)\n",
        "knn.fit(X_train,Y_train)\n",
        "acc=knn.evaluate(X_test,Y_test)\n",
        "print(acc)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6555023923444976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVzaTkqiseyq"
      },
      "source": [
        "class Adaline:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def fit(self,x_train,y_train):\n",
        "        # m=(X.T*X)^-1*X.T*Y\n",
        "        self.m=np.matmul(inv(np.matmul(x_train.T,x_train)),np.matmul(x_train.T,y_train))\n",
        "        return self.m\n",
        "    \n",
        "    def predict(self, x_test):\n",
        "        y_predict = np.matmul(x_test, self.m)\n",
        "        y=[]\n",
        "        for i in range(len(y_predict)):\n",
        "            if y_predict[i]<0.01:\n",
        "                y.append(0)\n",
        "            else:\n",
        "                y.append(1)  \n",
        "        y=np.array(y)\n",
        "        return y\n",
        "    \n",
        "    def evaluate(self,X_test,Y_test):\n",
        "        y_predict = self.predict(X_test)\n",
        "        count=0\n",
        "        for i in range(len(Y_test)):\n",
        "            if y_predict[i]==Y_test[i]:\n",
        "                count+=1\n",
        "        ev=count/len(Y_test)\n",
        "        return ev"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkbZG-lhsyo4",
        "outputId": "b219aa58-86e9-4806-987a-097f72cb9227"
      },
      "source": [
        "Adl=Adaline()\n",
        "Adl.fit(X_train,Y_train)\n",
        "y_pr=Adl.predict(X_test)\n",
        "acc=Adl.evaluate(X_test,Y_test)\n",
        "print(acc)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37559808612440193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZDm2R4ktbHW"
      },
      "source": [
        "class Perceptron():\n",
        "  def __init__(self):\n",
        "        self.w=np.random.rand(7,1)\n",
        "        self.b=np.random.rand(1,1)\n",
        "  def fit(self,lrate,ep,X,Y):\n",
        "      lr=lrate\n",
        "      epochs=ep\n",
        "\n",
        "      for j in range(7):\n",
        "          for i in range(X.shape[0]):\n",
        "            x_train = X[i].reshape(1,-1)\n",
        "            Y_pred = np.matmul(x_train, self.w)+self.b\n",
        "            e = Y[i] - Y_pred\n",
        "            self.w += lr * X[i]* e\n",
        "            self.b+=lr*e\n",
        "            \n",
        "            np.save('w', self.w)\n",
        "            np.save('b', self.b)\n",
        "\n",
        "      return Y_pred\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    w = np.load('w.npy')\n",
        "    b = np.load('b.npy')\n",
        "    Y=[]\n",
        "    for i in range(X_test.shape[0]):\n",
        "      y_pred=np.matmul(X_test[i],w)+b\n",
        "      if y_pred>0:\n",
        "          Y.append(1)\n",
        "      else:\n",
        "          Y.append(-1)\n",
        "    return Y\n",
        "\n",
        "\n",
        "  def accuracy(self,X_test,Y_test):\n",
        "    w = np.load('w.npy')\n",
        "    b = np.load('b.npy')\n",
        "    Y_pred=np.matmul(X_test,w)+b\n",
        "    count=0\n",
        "    for i in range(len(Y)):\n",
        "        if y_predict[i]==Y[i]:\n",
        "            count+=1\n",
        "    accuracy=count/len(Y)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "GgruLPB9yaa-",
        "outputId": "24c6c50a-9d41-4b94-db50-91274054e69f"
      },
      "source": [
        "prc=Perceptron()\n",
        "Y_train=Y_train.reshape(-1,1).T\n",
        "X_train=X_train.reshape(-1,7)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "Y_pred=prc.fit(0.001,100,X_train,Y_train)\n",
        "# y=prc.predict(X_test)\n",
        "# acc_test=evaluate_accuracy(X_test,Y_test)\n",
        "# print(acc)\n"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7)\n",
            "(1, 891)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-262-8595b8d2ffbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# y=prc.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# acc_test=evaluate_accuracy(X_test,Y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-261-559ac3a6293e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrate, ep, X, Y)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7,) (1,891) "
          ]
        }
      ]
    }
  ]
}