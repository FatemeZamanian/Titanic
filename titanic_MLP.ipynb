{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fV1_Ija-X5mgEOntMiPq1swFXXJD25Fb",
      "authorship_tag": "ABX9TyNm3dbcumfde3PLH9lPNCEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemeZamanian/Titanic/blob/master/titanic_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IH4X_MVBnaA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import inv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Qe-zqRuPExy8",
        "outputId": "37a38219-bccb-4ceb-b47f-3dd1636e0784"
      },
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "data=data.replace([\"male\",\"female\"],[0,1])\n",
        "data=data.replace([\"S\",\"C\",\"Q\"],[0,1,2])\n",
        "data=data.fillna(0)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500      0       0.0\n",
              "1            2         1       1  ...  71.2833    C85       1.0\n",
              "2            3         1       3  ...   7.9250      0       0.0\n",
              "3            4         1       1  ...  53.1000   C123       0.0\n",
              "4            5         0       3  ...   8.0500      0       0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgaZ-vZfJVaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713c46d8-9643-4b9a-bfee-ee43d4f4b398"
      },
      "source": [
        "Y_train=data[['Survived']]\n",
        "X_train=data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "Y_train=np.array(Y_train)\n",
        "X_train=np.array(X_train)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7)\n",
            "(891, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfQa2ujRYyVw"
      },
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Dense(7,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(512,activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dense(2,activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRX0ltfHB6TG"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqdjXgM0DZW6",
        "outputId": "6fb3c15b-f80c-43d6-a871-9f6f58befc04"
      },
      "source": [
        "out=model.fit(X_train,Y_train,epochs=500)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.6072\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.6195\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.6285\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6364\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.6554\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6813\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6633\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6599\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6689\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6622\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6453\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6622\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6712\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6700\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6521\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6588\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6768\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6712\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6902\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6790\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6790\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6622\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6891\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7091 - accuracy: 0.6465\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6891\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6734\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6756\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6824\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6813\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6689\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6689\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6925\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6700\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.6667\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6801\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6813\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6734\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6857\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6734\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6790\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6813\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6678\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6678\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6723\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6756\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6667\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6891\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6846\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6678\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6678\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6588\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6712\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6779\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6779\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6723\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6734\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6824\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6689\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6835\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6801\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6824\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6857\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6857\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6835\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6846\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6779\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6756\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6745\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.6813\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6824\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6734\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6813\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6745\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6768\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6824\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6801\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.6790\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6712\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6891\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6902\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6891\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6824\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6712\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6857\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6678\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6768\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6756\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6723\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6813\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6712\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6891\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6801\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.6857\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6790\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6756\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6689\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6790\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6667\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6891\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6880\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6790\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.6880\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6835\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6835\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6857\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6756\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6768\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6824\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6824\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6779\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6768\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6801\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6902\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6869\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6857\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6801\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6857\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6723\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6768\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6880\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6779\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6947\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6768\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6936\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6790\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6824\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6756\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6790\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.6824\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.6745\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6880\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6835\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6813\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6824\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6790\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6835\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6869\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6813\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.6824\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6824\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6869\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6824\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6846\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6835\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6869\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6768\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6756\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6779\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6869\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6813\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6824\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6914\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6835\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6813\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6891\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6723\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6768\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6756\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6835\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6813\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6869\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.6768\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6824\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6857\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6857\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6801\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6925\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6925\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6891\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6790\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6835\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6880\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6745\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6756\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6846\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6846\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6936\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7059\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6925\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6891\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6891\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6824\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6970\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6824\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6857\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6914\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6857\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6936\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6880\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6902\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6914\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6936\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6880\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6902\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6914\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6835\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6869\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6914\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6835\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6891\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6925\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6846\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6790\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6857\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6958\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6981\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6734\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6902\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6970\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7003\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6936\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6835\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6936\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6936\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6891\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6835\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6936\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6947\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7003\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6925\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6914\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6992\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6869\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6914\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.7037\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7037\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6947\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6970\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6992\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6981\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6857\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6992\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6970\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6902\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6970\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6869\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6790\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6981\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6947\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7071\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6925\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6925\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6925\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6914\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6947\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7059\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6880\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6936\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6981\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6981\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7003\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.6958\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6947\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6902\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6992\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7015\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7026\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6947\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7015\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6981\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6869\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6992\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6846\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7071\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7003\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.6958\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7048\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6958\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7082\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6936\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7003\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7059\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7037\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6992\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7149\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.6992\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6992\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6857\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7059\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7104\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7037\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7149\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6958\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7093\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6925\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.6981\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7082\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7026\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7015\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7127\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.6947\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6947\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7048\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.6970\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6981\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7082\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7127\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7149\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7104\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7082\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7127\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7138\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7093\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7071\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7295\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7015\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7116\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7059\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7093\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7183\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6981\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7104\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7059\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7127\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.6914\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7138\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7194\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7104\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7048\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7116\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7183\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7217\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7048\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7093\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7273\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7250\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7205\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7205\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7093\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7104\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7183\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7172\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7183\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7093\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7239\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7104\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7149\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7093\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7104\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7104\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7160\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7374\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7250\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7172\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7262\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7183\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7217\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7194\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7250\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7318\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7306\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7239\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7239\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7262\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6970\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7194\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7071\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7239\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7217\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7082\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7172\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7250\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7194\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7306\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7407\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7217\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7306\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7217\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7250\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7351\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7430\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7318\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7273\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7419\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7284\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7250\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7295\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7318\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7351\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7340\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7396\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7374\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7340\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7363\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7205\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7306\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7306\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7419\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7407\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7407\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7430\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7587\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7508\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7531\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7486\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7520\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7430\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7565\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7475\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7553\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7598\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7464\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7621\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7621\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7475\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7587\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7520\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7621\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7710\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7565\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7632\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7699\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7452\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7654\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7699\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7778\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7565\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7576\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7598\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7755\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7598\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7800\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7576\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7722\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7542\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7621\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7576\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7520\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7778\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7688\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7497\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7464\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7767\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7688\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7497\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7497\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7643\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7744\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7710\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7576\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7407\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7621\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7744\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7654\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7508\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7553\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7576\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7520\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7553\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7845\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7733\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7632\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7733\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7643\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7744\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7609\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7699\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7868\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7576\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7767\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7677\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7789\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7643\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7924\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7733\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7845\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7811\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7699\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7834\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7924\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7632\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7789\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7722\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7441\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7733\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7609\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7710\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7632\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7879\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7553\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7789\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7609\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7856\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7778\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7733\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7755\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7666\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7542\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7845\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7654\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7744\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7520\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7699\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7800\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7733\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7901\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7767\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7800\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7856\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "c9aA8Irws_dr",
        "outputId": "7448c888-40a1-4c05-901d-a5493128e49f"
      },
      "source": [
        "plt.plot(out.history['loss'])\n",
        "plt.plot(out.history['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3255a25990>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xAA-Z_A_mU_"
      },
      "source": [
        "data_test = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "data_test=data_test.replace([\"male\",\"female\"],[0,1])\n",
        "data_test=data_test.replace([\"S\",\"C\",\"Q\"],[0,1,2])\n",
        "data_test=data_test.fillna(0)\n",
        "\n",
        "X_test=data_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "\n",
        "Y = pd.read_csv('/content/drive/MyDrive/gender_submission.csv')\n",
        "Y_test = Y[['Survived']]\n",
        "\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TfaJjM2G-lX",
        "outputId": "691f7f54-d99c-4a93-880a-ef8d4b74ef75"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3701232373714447, 0.8827751278877258]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqSmiOzNH5LO",
        "outputId": "05e0e939-be56-4580-84b2-8572852e7981"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "predict = np.argmax(Y_pred, axis = 1)\n",
        "predict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouaPqXgCd-93",
        "outputId": "03fa0d94-92db-4b54-c1e8-d099de39a922"
      },
      "source": [
        "model.save('/content/drive/MyDrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCDk2hY3eTCO"
      },
      "source": [
        "class KNearestNeighbors:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        \n",
        "    def fit(self, x_train, y_train):\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.number_class = len(np.unique(y_train))\n",
        "        \n",
        "    def distance(self,a,b):\n",
        "        dis = np.sqrt(np.sum((a-b)**2, axis = 1))\n",
        "        return dis\n",
        "        \n",
        "    def nearestNeighbors(self, x_test):\n",
        "        point_dist=[]\n",
        "        for x in x_test:\n",
        "            point_dist.append(self.distance(x,self.x_train))\n",
        "            \n",
        "        neigh_ind=[]\n",
        "        for row in point_dist:\n",
        "            near_neighbor = np.argsort(row)[:self.k]\n",
        "            neigh_ind.append(near_neighbor)\n",
        "            \n",
        "        return np.array(neigh_ind)\n",
        "    \n",
        "    def predict(self, x_test):\n",
        "        neighbors = self.nearestNeighbors(x_test)\n",
        "        y_pred=[]\n",
        "        for neighbor in neighbors:\n",
        "            y_pred.append(np.argmax(np.bincount(self.y_train[neighbor])))\n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def evaluate(self,x_test,y_test):\n",
        "        temp=[]\n",
        "        c=0\n",
        "        self.x_test=x_test\n",
        "        self.y_test=y_test\n",
        "        temp=self.predict(self.x_test)\n",
        "        for i in range(len(self.x_test)):\n",
        "            if temp[i]==self.y_test[i]:\n",
        "                c+=1\n",
        "        ev=c/len(y_test)\n",
        "        return ev"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dajw-vpxf44m",
        "outputId": "7129671d-b12c-43c4-abbd-afbd13193893"
      },
      "source": [
        "Y_train = Y_train.reshape(-1,)\n",
        "knn=KNearestNeighbors(k=5)\n",
        "knn.fit(X_train,Y_train)\n",
        "acc=knn.evaluate(X_test,Y_test)\n",
        "print(acc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6555023923444976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVzaTkqiseyq"
      },
      "source": [
        "class Adaline:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def fit(self,x_train,y_train):\n",
        "        # m=(X.T*X)^-1*X.T*Y\n",
        "        self.m=np.matmul(inv(np.matmul(x_train.T,x_train)),np.matmul(x_train.T,y_train))\n",
        "        return self.m\n",
        "    \n",
        "    def predict(self, x_test):\n",
        "        y_predict = np.matmul(x_test, self.m)\n",
        "        y=[]\n",
        "        for i in range(len(y_predict)):\n",
        "            if y_predict[i]<0.01:\n",
        "                y.append(0)\n",
        "            else:\n",
        "                y.append(1)  \n",
        "        y=np.array(y)\n",
        "        return y\n",
        "    \n",
        "    def evaluate(self,X_test,Y_test):\n",
        "        y_predict = self.predict(X_test)\n",
        "        count=0\n",
        "        for i in range(len(Y_test)):\n",
        "            if y_predict[i]==Y_test[i]:\n",
        "                count+=1\n",
        "        ev=count/len(Y_test)\n",
        "        return ev"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkbZG-lhsyo4",
        "outputId": "b527bddb-473d-480a-95b1-b4ef776f436b"
      },
      "source": [
        "Adl=Adaline()\n",
        "Adl.fit(X_train,Y_train)\n",
        "y_pr=Adl.predict(X_test)\n",
        "acc=Adl.evaluate(X_test,Y_test)\n",
        "print(acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37559808612440193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZDm2R4ktbHW"
      },
      "source": [
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    self.w = np.random.rand(7, 1)\n",
        "    self.b = np.random.rand(1, 1)\n",
        "  def fit(self,lrate,ep,X,Y):\n",
        "    self.X_train = X_train\n",
        "    self.Y_train = Y_train\n",
        "    self.number_class = len(np.unique(Y_train))\n",
        "    lr=lrate\n",
        "    epochs=ep\n",
        "\n",
        "    for j in range(epochs):\n",
        "        for i in range(X.shape[0]):\n",
        "          Y_pred = np.matmul(self.X_train[i], self.w) + self.b\n",
        "          e = self.Y_train[i] - Y_pred\n",
        "          a = lr * self.X_train[i, :].T * e\n",
        "          \n",
        "          self.w += a.T\n",
        "          self.b += lr * e\n",
        "          \n",
        "          np.save('w', self.w)\n",
        "          np.save('b', self.b)\n",
        "\n",
        "    return Y_pred\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    w = np.load('w.npy')\n",
        "    b = np.load('b.npy')\n",
        "    Y_pred = np.matmul(X_test, w) + b\n",
        "    predic = []\n",
        "    for pred in (Y_pred):\n",
        "      if pred > 1:\n",
        "          predic.append([1])\n",
        "      elif pred < 1:\n",
        "          predic.append([0])\n",
        "    return predic\n",
        "\n",
        "  \n",
        "  def evaluate_acc(self,X_test,Y_test):\n",
        "    w = np.load('w.npy')\n",
        "    b = np.load('b.npy')\n",
        "    Y_pred=self.predict(X_test)\n",
        "    count=0\n",
        "    for i in range(len(Y_test)):\n",
        "      if Y_pred[i]==Y_test[i]:\n",
        "        count+=1\n",
        "    acc=count/len(Y_test)\n",
        "    return acc\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgruLPB9yaa-",
        "outputId": "96370791-9320-4729-f769-cb553f645c1b"
      },
      "source": [
        "Y_train = Y_train.reshape(-1,1)\n",
        "prc = Perceptron()\n",
        "y = prc.fit(0.001,2,X_train, Y_train)\n",
        "prc.predict(X_test)\n",
        "acc = prc.evaluate_acc(X_test,Y_test)\n",
        "print(acc)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3803827751196172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPo4rU8WyZ3F"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}